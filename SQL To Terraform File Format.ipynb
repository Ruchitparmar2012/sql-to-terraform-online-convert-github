{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a58084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL File Format To Terraform File Format\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Specify the relative folder path containing .sql files\n",
    "relative_folder_path = 'SQL_Files/File_Format'\n",
    "\n",
    "# Combine the current working directory with the relative folder path\n",
    "folder_path = os.path.join(current_directory, relative_folder_path)\n",
    "\n",
    "try:\n",
    "    # Get a list of all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    # Filter out only the .sql files\n",
    "    sql_files = [file for file in files if file.endswith('.sql')]\n",
    "\n",
    "    # Read the contents of each .sql file and store them in a list\n",
    "    sql_contents_list = []\n",
    "    for sql_file in sql_files:\n",
    "        file_path = os.path.join(folder_path, sql_file)\n",
    "        with open(file_path, 'r') as file:\n",
    "            sql_contents = file.read()\n",
    "            sql_contents_list.append(sql_contents)\n",
    "            \n",
    "except FileNotFoundError:\n",
    "    print(f\"Folder not found: {folder_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "import re\n",
    "# this code remove double quotes outside form DDL / Including Database, schema, table name \n",
    "def remove_outer_quotes(sql):\n",
    "    ls1 = sql.split(\"(\")[0].replace('\"','')\n",
    "    ls2 = [\"(\"+i for i in sql.split(\"(\")[1:]] \n",
    "    ls2.insert(0,ls1)\n",
    "    sql = \"\".join(ls2)  \n",
    "    \n",
    "    return sql\n",
    "resource_File_Format_name_list = []\n",
    "\n",
    "# main python code \n",
    "def python_terraform(sql):\n",
    "    code = \"\"\n",
    "    ddl = sql.split(';')\n",
    "\n",
    "    for command in ddl:\n",
    "        command = command.strip().upper()\n",
    "        create_command = re.findall(r\"CREATE(?:\\s+OR\\s+REPLACE)?\\s+FILE FORMAT\\s+(.*?)\\.(.*?)\\.(.*?)\\s+\", command, re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "        if create_command:\n",
    "            database_name, schema_name, table_name = create_command[0]\n",
    " \n",
    "            # set the dynamic database name / remove dev, prod name\n",
    "            dynamic_db = ''\n",
    "            dynamic__main_db = ''\n",
    "            if database_name.endswith(\"_DEV\"):\n",
    "                dynamic_db += database_name.replace(\"_DEV\", \"_${var.SF_ENVIRONMENT}\")\n",
    "                dynamic__main_db += database_name.replace(\"_DEV\", \"\")\n",
    "            elif database_name.endswith(\"_PROD\"):\n",
    "                dynamic_db += database_name.replace(\"_PROD\", \"_${var.SF_ENVIRONMENT}\")\n",
    "                dynamic__main_db += database_name.replace(\"_PROD\", \"\")\n",
    "            \n",
    "            # --------------------------------------------------------------------------------------\n",
    "            # this pattern for Compression\n",
    "            Compression_match = re.search(r'compression\\s*=\\s*([\\w\\d]+)', sql, re.IGNORECASE)\n",
    "            \n",
    "            # this pattern for file type\n",
    "            type_match = re.search(r'type\\s*=\\s*\\'([^\\']+)\\'', sql, re.IGNORECASE)\n",
    "  \n",
    "            # this pattern for field delimiter\n",
    "            field_delimiter_match = re.search(r'field_delimiter\\s*=\\s*\\'([^\\']+)\\'', sql, re.IGNORECASE)\n",
    "\n",
    "            # this pattern for Encoding\n",
    "            Encoding_match = re.search(r'encoding\\s*=\\s*\\'([^\\']+)\\'', sql, re.IGNORECASE)\n",
    "\n",
    "            # this pattern for skip header   \n",
    "            skip_header_match = re.search(r'skip_header\\s*=\\s*(\\d+)', sql, re.IGNORECASE)\n",
    "            \n",
    "            # --------------------------------------------------------------------------------------\n",
    "            # create File Format  \n",
    "            resource_File_Format_name = f\"resource \\\"snowflake_file_format\\\" \\\"{dynamic__main_db}_{schema_name}_{table_name}\\\"\"\n",
    "            code += f\"{resource_File_Format_name} {{\\n\"\n",
    "            code += f\"\\tname = \\\"{table_name}\\\"\\n\"\n",
    "            code += f\"\\tdatabase = \\\"{dynamic_db}\\\"\\n\"\n",
    "            resource_File_Format_name_demo = f'{dynamic__main_db}_{schema_name}_{table_name}'\n",
    "            resource_File_Format_name_list.append(resource_File_Format_name_demo)\n",
    "            code += f\"\\tschema = \\\"{schema_name}\\\"\\n\"\n",
    "            \n",
    "            if Compression_match:\n",
    "                compression_value = Compression_match.group(1)\n",
    "                code += f\"\\tcompression = \\\"{compression_value}\\\"\\n\"\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            if Encoding_match:\n",
    "                encoding_value = Encoding_match.group(1)\n",
    "                code += f\"\\tencoding = \\\"{encoding_value}\\\"\\n\"\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            if field_delimiter_match:\n",
    "                field_delimiter_value = field_delimiter_match.group(1)\n",
    "                code += f\"\\tfield_delimiter = \\\"{field_delimiter_value}\\\"\\n\"\n",
    "            else:\n",
    "                pass\n",
    "      \n",
    "            \n",
    "            if skip_header_match:\n",
    "                skip_header_value = skip_header_match.group(1)\n",
    "                code += f\"\\tskip_header = {skip_header_value}\\n\"\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            if type_match:\n",
    "                type_value = type_match.group(1)    \n",
    "                code += f\"\\tformat_type = \\\"{type_value}\\\"\\n\"\n",
    "            else:\n",
    "                pass\n",
    "       \n",
    "            code += \"}\\n\\n\"\n",
    "\n",
    "    return code\n",
    "\n",
    "\n",
    "# Process each SQL content and generate Terraform code\n",
    "for sql_contents in sql_contents_list:\n",
    "    sql_without_quotes = remove_outer_quotes(sql_contents)\n",
    "    main = python_terraform(sql_without_quotes)\n",
    "\n",
    "output_folder = os.path.join(current_directory, 'Terraform_Files','File Format')\n",
    "\n",
    "try:\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while creating the output folder: {e}\")\n",
    "\n",
    "for i, sql_contents in enumerate(sql_contents_list):\n",
    "    sql_without_quotes = remove_outer_quotes(sql_contents)\n",
    "    main = python_terraform(sql_without_quotes)\n",
    "\n",
    "    for i in resource_File_Format_name_list:\n",
    "        resource_name = i \n",
    "        output_filename = os.path.join(output_folder, f\"{resource_name}.tf\")\n",
    "     \n",
    "    try:\n",
    "        with open(output_filename, 'w') as tf_file:\n",
    "            tf_file.write(main)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while writing the output file: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
